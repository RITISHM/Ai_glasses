


<div align="center">

# ğŸ§  AI Glasses â€” Real-Time Voice Assistant  
### *with ESP32-S3 Sense & Flask Backend*

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg?style=flat&logo=python)
![Flask](https://img.shields.io/badge/Flask-Backend-black.svg?style=flat&logo=flask)
![ESP32](https://img.shields.io/badge/ESP32--S3-Firmware-orange.svg?style=flat&logo=espressif)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=flat)
![Status](https://img.shields.io/badge/Status-Active-success.svg?style=flat)

> âš¡ï¸ AI-powered wearable assistant that **listens, sees, and speaks** â€” built for **edge efficiency** and **real-time intelligence**.

</div>

---

## âœ¨ Overview

This project brings **AI-powered smart glasses** to life using the **ESP32-S3 Sense** board.  
It captures **voice and image data**, streams it to a **Flask backend**, and delivers **spoken responses** in real time using **Pyttsx3** and a **MAX98357 DAC**.

Itâ€™s designed for **ultra-low latency**, **modular architecture**, and **ethical edge AI** deployment.

---

## ğŸ”§ Features

- ğŸ™ï¸ **Voice Capture** via ESP32-S3 MEMS microphone  
- ğŸ“· **Image Capture** using onboard camera  
- ğŸ“¡ **Audio & Image Streaming** to Flask server  
- ğŸ§  **Speech-to-Text (ASR)** via FasterWhisper  
- ğŸ¤– **AI Response Generation** using OpenAI API or local model  
- ğŸ”Š **Text-to-Speech (TTS)** using Pyttsx3 (WAV output)  
- ğŸ” **Audio Playback** via MAX98357 DAC (I2S)  
- ğŸ§© **Modular Flask Pipeline** â€” ASR, LLM, TTS separated cleanly  

---

## ğŸ—ï¸ Architecture

```

[ESP32-S3 Sense]
â”œâ”€ Record audio (MEMS mic)
â”œâ”€ Capture image (camera)
â””â”€ POST to Flask server
â”œâ”€ Transcribe audio â†’ FasterWhisper
â”œâ”€ Generate response â†’ LLM API
â”œâ”€ Convert response to WAV â†’ Pyttsx3
â””â”€ Stream WAV back to ESP32
â””â”€ Playback via MAX98357 DAC (I2S)

```

---

## ğŸ“ Project Structure

```

AI-Glasses/
â”‚
â”œâ”€â”€ esp32/          # Arduino firmware for ESP32-S3
â”œâ”€â”€ server/         # Flask backend with REST endpoints
â”œâ”€â”€ asr/            # FasterWhisper transcription wrapper
â”œâ”€â”€ llm/            # LLM query handler (OpenAI / Local)
â”œâ”€â”€ tts/            # Pyttsx3-based Text-to-Speech module
â””â”€â”€ utils/          # Logging, preprocessing, buffer management

````

---

## âš™ï¸ Setup & Installation

### ğŸ”Œ ESP32-S3 Firmware

1. Flash the code in `esp32/main.ino`  
2. Configure **WiFi credentials** and **Flask server IP**  
3. Connect **MAX98357 DAC** to I2S pins  
4. Press the button to trigger **recording + image capture**

---

### ğŸ–¥ï¸ Flask Backend Setup

```bash
# 1ï¸âƒ£ Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 3ï¸âƒ£ Run Flask server
python server/app.py
````

> ğŸ’¡ Tip: Use `ngrok` or local tunnel for quick remote testing between your PC and ESP32.

---

## ğŸ” Data Flow

| Step | Process                      | Description                          |
| ---- | ---------------------------- | ------------------------------------ |
| 1ï¸âƒ£  | ğŸ™ï¸ Audio & ğŸ“· Image Capture | ESP32 records and snaps image        |
| 2ï¸âƒ£  | ğŸ“¡ Upload                    | Data sent via HTTP POST to Flask     |
| 3ï¸âƒ£  | ğŸ§  Transcription             | FasterWhisper converts speech â†’ text |
| 4ï¸âƒ£  | ğŸ¤– Response Generation       | LLM creates smart reply              |
| 5ï¸âƒ£  | ğŸ”Š TTS                       | Pyttsx3 converts text â†’ WAV          |
| 6ï¸âƒ£  | ğŸš€ Streaming                 | Flask streams WAV back to ESP32      |
| 7ï¸âƒ£  | ğŸ”ˆ Playback                  | ESP32 plays response via DAC         |

---

## ğŸ§ª Testing & Benchmarking

| Test             | Goal                               | Metric                       |
| ---------------- | ---------------------------------- | ---------------------------- |
| â±ï¸ Latency       | Measure from audio POST â†’ playback | Time (ms)                    |
| ğŸ—£ï¸ ASR Accuracy | Validate transcription             | WER (Word Error Rate)        |
| ğŸ¤– LLM Quality   | Evaluate response clarity          | Coherence, Context           |
| ğŸ”‰ Audio         | Check playback quality             | Subjective & objective tests |

---

## ğŸ—ºï¸ Roadmap

* [ ] ğŸ—£ï¸ Add **Speaker Diarization** for multi-user dialogue
* [ ] ğŸ§  Integrate **Local LLM** for offline use
* [ ] âš¡ Optimize **Buffer Handling** for XIAO ESP32-S3 (no PSRAM)
* [ ] ğŸ•¶ï¸ Develop **Wearable Form Factor** (mini speaker + battery)
* [ ] ğŸ‘ï¸ Add **Image-based prompt enrichment** (â€œDescribe this sceneâ€)

---

## ğŸ’¡ Philosophy

> *â€œAI should amplify human potential â€” not replace it.â€*

This project embodies:

* ğŸ§© **Modularity** â€” each part can evolve independently
* âš¡ **Edge Efficiency** â€” minimal latency, privacy-first design
* ğŸ¤ **Ethical AI** â€” transparency, respect, and control

---

## ğŸ“œ License

This project is released under the **MIT License** â€” use, adapt, and improve freely.

---

<div align="center">

### ğŸŒŸ Inspiration

> *Combining the worlds of AI, IoT, and wearable tech â€” transforming the ESP32-S3 into a real-time conversational companion.*

**Made with â¤ï¸ and â˜• by innovators who believe in edge AI.**

</div>
```

